{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpp/anaconda3/envs/conv/lib/python3.8/site-packages/proplot/__init__.py:46: ProPlotWarning: Ignoring the following .ttc fonts because they cannot be saved into PDF or EPS files (see matplotlib issue #3135): '/home/hpp/.config/proplot/fonts/Sitka.ttc', '/home/hpp/.config/proplot/fonts/SitkaB.ttc', '/home/hpp/.config/proplot/fonts/SitkaI.ttc', '/home/hpp/.config/proplot/fonts/SitkaZ.ttc', '/home/hpp/.config/proplot/fonts/YuGothB.ttc', '/home/hpp/.config/proplot/fonts/YuGothL.ttc', '/home/hpp/.config/proplot/fonts/YuGothM.ttc', '/home/hpp/.config/proplot/fonts/YuGothR.ttc', '/home/hpp/.config/proplot/fonts/cambria.ttc', '/home/hpp/.config/proplot/fonts/mingliub.ttc', '/home/hpp/.config/proplot/fonts/msgothic.ttc', '/home/hpp/.config/proplot/fonts/msjh.ttc', '/home/hpp/.config/proplot/fonts/msjhbd.ttc', '/home/hpp/.config/proplot/fonts/msjhl.ttc', '/home/hpp/.config/proplot/fonts/msyh.ttc', '/home/hpp/.config/proplot/fonts/msyhbd.ttc', '/home/hpp/.config/proplot/fonts/msyhl.ttc', '/home/hpp/.config/proplot/fonts/simsun.ttc'. Please consider expanding them into separate .ttf files.\n",
      "  register_fonts(default=True)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import metpy.calc\n",
    "from metpy.calc import cape_cin, dewpoint_from_relative_humidity, parcel_profile, showalter_index,equivalent_potential_temperature,get_layer,moist_lapse\n",
    "from metpy.units import units\n",
    "from wrf import interpz3d,getvar\n",
    "from numpy import sqrt,mod,arctan2\n",
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import xlrd\n",
    "import xlwt\n",
    "import matplotlib \n",
    "import proplot as pplt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdate\n",
    "from netCDF4 import Dataset\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_high='/mnt/d/hpp_onedrive/OneDrive/work/data/era5/20210415.nc'\n",
    "# file_surf='/mnt/d/hpp_onedrive/OneDrive/work/data/era5/20210415-sfc.nc'\n",
    "file_high='/mnt/d/OneDrive/work/data/era5/20210415.nc'\n",
    "file_surf='/mnt/d/OneDrive/work/data/era5/20210415-sfc.nc'\n",
    "\n",
    "##3333333333333333333333世界时\n",
    "time_star=7\n",
    "time_end =22\n",
    "time= pd.date_range('2021-04-15-07','2021-04-15-21',freq='H')\n",
    "###33333333333333333333333北京时\n",
    "day='2021_041515-1605'\n",
    "# label=['15-15','15-16','15-17','15-18','15-19','15-20','15-21','15-22','15-23','16-00','16-01','16-02','16-03','16-04','16-05']#,'29-02','29-03']#,'16-01','16-02','16-03','16-04','16-05']\n",
    "\n",
    "era_high=xr.open_dataset(file_high)\n",
    "geo_time=era_high['z'][time_star:time_end,::-1,::-1,:]##################################################\n",
    "z_time=metpy.calc.geopotential_to_height(geo_time)\n",
    "p_time=era_high['z'][time_star:time_end,:,:,:]['level'].values[::-1]* units.hPa\n",
    "r_time=era_high['r'][time_star:time_end,::-1,::-1,:]*0.01\n",
    "t_time=era_high['t'][time_star:time_end,::-1,::-1,:]-273.15\n",
    "u_time=era_high['u'][time_star:time_end,::-1,::-1,:]\n",
    "v_time=era_high['v'][time_star:time_end,::-1,::-1,:]\n",
    "w_time=era_high['w'][time_star:time_end,::-1,::-1,:]\n",
    "era_surf=xr.open_dataset(file_surf)\n",
    "u10_time=era_surf['u10'][time_star:time_end,::-1,:]\n",
    "v10_time=era_surf['v10'][time_star:time_end,::-1,:]\n",
    "\n",
    "dur=time_end-time_star\n",
    "var=['CAPE','LI','DCAPE','SWEAT','800-500','0-3KM','0-6KM']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读连续文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_high_0='/mnt/d/hpp_onedrive/OneDrive/work/era5/20200809.nc'\n",
    "file_surf_0='/mnt/d/hpp_onedrive/OneDrive/work/era5/20200809-sfc.nc'\n",
    "file_surf_1='/mnt/d/hpp_onedrive/OneDrive/work/era5/20200810-sfc.nc'\n",
    "file_high_1='/mnt/d/hpp_onedrive/OneDrive/work/era5/20200810.nc'\n",
    "\n",
    "era_high_0=xr.open_dataset(file_high_0)\n",
    "era_high_1=xr.open_dataset(file_high_1)\n",
    "era_surf_0=xr.open_dataset(file_surf_0)\n",
    "era_surf_1=xr.open_dataset(file_surf_1)\n",
    "era_high=xr.concat([era_high_0,era_high_1],dim=\"time\")\n",
    "era_surf=xr.concat([era_surf_0,era_surf_1],dim=\"time\")\n",
    "\n",
    "#世界时\n",
    "time_star=16\n",
    "time_end =25\n",
    "###北京时\n",
    "day='20_081000-1008'\n",
    "label=['10-00','10-01','10-02','10-03','10-04','10-05','10-06','10-07','10-08']#,'05-02','05-03','05-04','05-05','05-06','05-07','05-08','05-09','05-10','05-11']\n",
    "\n",
    "geo_time=era_high['z'][time_star:time_end,::-1,::-1,:]##################################################\n",
    "z_time=metpy.calc.geopotential_to_height(geo_time)\n",
    "p_time=era_high['z'][time_star:time_end,:,:,:]['level'].values[::-1]* units.hPa\n",
    "r_time=era_high['r'][time_star:time_end,::-1,::-1,:]*0.01\n",
    "t_time=era_high['t'][time_star:time_end,::-1,::-1,:]-273.15\n",
    "u_time=era_high['u'][time_star:time_end,::-1,::-1,:]\n",
    "v_time=era_high['v'][time_star:time_end,::-1,::-1,:]\n",
    "w_time=era_high['w'][time_star:time_end,::-1,::-1,:]\n",
    "\n",
    "u10_time=era_surf['u10'][time_star:time_end,::-1,:]\n",
    "v10_time=era_surf['v10'][time_star:time_end,::-1,:]\n",
    "\n",
    "dur=time_end-time_star\n",
    "time = np.arange(dur)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dcape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downdraft_cape(pressure, temperature, dewpoint, parcel=None, bottom=None,\n",
    "                    depth=400 * units.hPa):\n",
    "    r\"\"\"Calculate downdraft CAPE.\n",
    "    Calculate the downdraft convective available potential energy (CAPE).The minimum theta-e\n",
    "    value between the surface and top_pressure is used as the parcel starting point. Parcels\n",
    "    descend along a moist adiabat. Area between the parcel path and environmental temperature\n",
    "    is integrated to calculate DCAPE.\n",
    "    Parameters\n",
    "    ----------\n",
    "    pressure : `pint.Quantity`\n",
    "        The atmospheric pressure level(s) of interest. The first entry should be the starting\n",
    "        point pressure.\n",
    "    temperature : `pint.Quantity`\n",
    "        The atmospheric temperature corresponding to pressure.\n",
    "    dewpoint : `pint.Quantity`\n",
    "        The atmospheric dew point corresponding to pressure.\n",
    "    parcel : tuple\n",
    "        Tuple of pressure and temperature for the starting parcel.\n",
    "    bottom : `pint.Quantity`\n",
    "        Lowest point in the parcel path to consider in integration in height or pressure.\n",
    "        If no heights are given, a standard atmosphere will be assumed. Defaults to None.\n",
    "    top_pressure : `pint.Quantity`\n",
    "        The lowest pressure value to be considered in the calculation. Defaults to 400 hPa.\n",
    "    Returns\n",
    "    -------\n",
    "    `pint.Quantity`\n",
    "        Downdraft convective available potential energy (CAPE).\n",
    "    Notes\n",
    "    -----\n",
    "    .. math:: \\text{DCAPE} = R_d \\int_{P_i}^{P_{sfc}} (T_{env} - T_{parcel}) d\\text{ln}(p)\n",
    "    * :math:`DCAPE` Downdraft convective available potential energy\n",
    "    * :math:`R_d` Gas constant\n",
    "    * :math:`g` Gravitational acceleration\n",
    "    * :math:`T_{parcel}` Parcel temperature\n",
    "    * :math:`T_{env}` Environment temperature\n",
    "    * :math:`p` Atmospheric pressure\n",
    "    \"\"\"\n",
    "\n",
    "    # If the user specified a parcel starting point, we'll use that instead of the default\n",
    "    if parcel:\n",
    "        if depth:\n",
    "            ValueError('Cannot specify a depth when using a custom parcel.')\n",
    "\n",
    "        parcel_starting_pressure, parcel_starting_temperature = parcel\n",
    "\n",
    "        # If no bottom is specified, we'll use the surface (default of get_layer),but\n",
    "        # done explicitly here to depth calculation.\n",
    "        if not bottom:\n",
    "            bottom = np.nanmax(pressure) * pressure.units\n",
    "\n",
    "        # Calculate the depth of the sounding to use (bottom - the parcel starting point)\n",
    "        depth = bottom - parcel_starting_pressure\n",
    "\n",
    "        # Trim data to the bottom and depth above it\n",
    "        pressure, temperature = get_layer(pressure, temperature, bottom=bottom,\n",
    "                                          depth=depth)\n",
    "\n",
    "    # # The user did not give us a parcel, so we'll calculate a sensible default.\n",
    "\n",
    "    else:\n",
    "\n",
    "        # Trim data to only top height and below as well as bottom height and above\n",
    "        pressure, temperature, dewpoint = get_layer(pressure, temperature, dewpoint,\n",
    "                                                    depth=depth,\n",
    "                                                    bottom=bottom\n",
    "                                                    )\n",
    "\n",
    "        # Find minimum theta-e\n",
    "        theta_e = equivalent_potential_temperature(pressure, temperature, dewpoint)\n",
    "        minimum_theta_e_index = np.argmin(theta_e)\n",
    "\n",
    "        # Trim data to be minimum theta-e down (dewpoint is no longer required)\n",
    "        if len(pressure[:minimum_theta_e_index]) != 0:\n",
    "            \n",
    "            pressure = pressure[:minimum_theta_e_index]\n",
    "            temperature = temperature[:minimum_theta_e_index]\n",
    "\n",
    "            # Sort for monotonically increasing pressure that trapz needs to work.\n",
    "            # Also guarantees the logic for calculating a descending parcel is sound.\n",
    "            sort_inds = np.argsort(pressure)\n",
    "            pressure = pressure[sort_inds]\n",
    "            temperature = temperature[sort_inds]\n",
    "\n",
    "            # Create the parcel profile for decent along a moist adiabat\n",
    "            profile_temperatures = moist_lapse(pressure, temperature[0])\n",
    "\n",
    "            # Calculate the difference in profile and environmental temperature to integrate\n",
    "\n",
    "            y_vals = temperature - profile_temperatures\n",
    "\n",
    "            # Calculate DCAPE\n",
    "            dcape = metpy.constants.dry_air_gas_constant * (np.trapz(y_vals,\n",
    "                                x=np.log(pressure.m)) )\n",
    "        else:\n",
    "            dcape=np.nan*units('J/kg')\n",
    "    return dcape.to('J/kg')#, pressure[::-1], profile_temperatures[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 区域"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-43-84e26c7a99e8>:7: UserWarning: Relative humidity >120%, ensure proper units.\n",
      "  Td = dewpoint_from_relative_humidity(t_mean, r_mean)\n",
      "<ipython-input-43-84e26c7a99e8>:7: UserWarning: Relative humidity >120%, ensure proper units.\n",
      "  Td = dewpoint_from_relative_humidity(t_mean, r_mean)\n",
      "<ipython-input-43-84e26c7a99e8>:7: UserWarning: Relative humidity >120%, ensure proper units.\n",
      "  Td = dewpoint_from_relative_humidity(t_mean, r_mean)\n",
      "/home/hpp/anaconda3/envs/conv/lib/python3.8/site-packages/metpy/calc/thermo.py:1396: RuntimeWarning: invalid value encountered in log\n",
      "  val = np.log(vapor_pressure / mpconsts.nounit.sat_pressure_0c)\n"
     ]
    }
   ],
   "source": [
    "# var=np.zeros((dur,var_num))\n",
    "var_mean=pd.DataFrame(columns=['CAPE', 'LI', 'DCAPE','SWEAT','800-500','0-3KM','0-6KM'], index=time)\n",
    "for i in range(0,dur):\n",
    "    #CAPE   \n",
    "    t_mean=((t_time[i,:,:,:].loc[:,36.1:41.5,117.5:122.5]) )* units.degC\n",
    "    r_mean=(r_time[i,:,:,:].loc[:,36.1:41.5,117.5:122.5])* units.dimensionless\n",
    "    Td = dewpoint_from_relative_humidity(t_mean, r_mean)\n",
    "    prof= parcel_profile(p_time, np.mean(t_mean,axis=(1,2))[0], np.mean(Td,axis=(1,2))[0]).to('degC')\n",
    "    var_mean['CAPE'][i]=cape_cin(p_time, np.mean(t_mean,axis=(1,2)), np.mean(Td,axis=(1,2)), prof)[0].magnitude #cape\n",
    "    # #LI\n",
    "    var_mean['LI'][i]=metpy.calc.lifted_index(p_time, np.mean(t_mean,axis=(1,2)), prof, vertical_dim=0)[0].magnitude #li\n",
    "    # #DCAPE\n",
    "    var_mean['DCAPE'][i]=downdraft_cape(p_time, np.mean(t_mean,axis=(1,2)), np.mean(Td,axis=(1,2))).magnitude\n",
    "    #sweat\n",
    "    wspd=sqrt( (u_time[i,:,:,:].loc[:,36.1:41.5,117.5:122.5])*(u_time[i,:,:,:].loc[:,36.1:41.5,117.5:122.5])+\n",
    "            (v_time[i,:,:,:].loc[:,36.1:41.5,117.5:122.5])*(v_time[i,:,:,:].loc[:,36.1:41.5,117.5:122.5]) )*units.knot\n",
    "#     wdir=mod(180.0+arctan2(u_time[i,:,:,:].loc[:,36.1:41.5,117.5:122.5],v_time[i,:,:,:].loc[:,36.1:41.5,117.5:122.5]),360.0)\n",
    "    wdir=metpy.calc.wind_direction(u_time[i,:,:,:].loc[:,36.1:41.5,117.5:122.5], v_time[i,:,:,:].loc[:,36.1:41.5,117.5:122.5], convention='from')\n",
    "    var_mean['SWEAT'][i]=metpy.calc.sweat_index(p_time,np.mean(t_mean,axis=(1,2)),np.mean(Td,axis=(1,2)),wspd.mean(),wdir.mean(),vertical_dim=0)[0].magnitude  #sweat\n",
    "    #xiangdangweiwen\n",
    "    var_mean['800-500'][i] = equivalent_potential_temperature(p_time, np.mean(t_mean,axis=(1,2)), np.mean(Td,axis=(1,2)) )[6].values-equivalent_potential_temperature(p_time, np.mean(t_mean,axis=(1,2)), np.mean(Td,axis=(1,2)) )[15].values \n",
    "    #0-3km shear\n",
    "    z_list=[6000,3000] #unit:m\n",
    "    u_height = interpz3d(u_time[i,:,:,:].loc[:,36.1:41.5,117.5:122.5],z_time[i,:,:,:].loc[:,36.1:41.5,117.5:122.5],np.array(z_list))\n",
    "    v_height = interpz3d(v_time[i,:,:,:].loc[:,36.1:41.5,117.5:122.5],z_time[i,:,:,:].loc[:,36.1:41.5,117.5:122.5],np.array(z_list))\n",
    "    var_mean['0-3KM'][i]=( ((u_height[1,:,:]-u10_time[i,:,:].loc[36.1:41.5,117.5:122.5])**2+(v_height[1,:,:]-v10_time[i,:,:].loc[36.1:41.5,117.5:122.5])**2)**(1/2) ).mean().values #3km\n",
    "    #0-6km shear\n",
    "    var_mean['0-6KM'][i]=( ((u_height[0,:,:]-u10_time[i,:,:].loc[36.1:41.5,117.5:122.5])**2+(v_height[0,:,:]-v10_time[i,:,:].loc[36.1:41.5,117.5:122.5])**2)**(1/2) ).mean().values #6km\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 站点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sta=['54539','54662','54778',\n",
    "'D3118','D2002','54741','54538','54721','54449','54720','54647','54641','54544',\n",
    "'L5070','L2245','L5069','L2215','L2239','L6081',\n",
    "'A3171',\n",
    "'54548','54642','54646','54639','54743','54649','54654','54552','54560','54464','54465']\n",
    "\n",
    "sta_lon=[118.89,121.64,122.48,\n",
    "119.1883,119.1914,118.8125,118.4544,117.8836,119.5103,117.7089,118.8742,118.5483,119.2792,\n",
    "121.47,121.8769,121.0553,121.5136,121.3819,122.0742,\n",
    "117.7892,\n",
    "119.3583,119.3325,118.4131,119.0656,119.5492,119.8331,120.1508,120.6117,121.0583,121.1044,121.4128]\n",
    "\n",
    "sta_lat=[39.43,38.91,37.17,\n",
    "37.7589,37.2511,38.2153,39.0836,38.3431,39.8469,38.4575,39.1681,38.855,39.5683,\n",
    "40.94,39.9833,40.7933,39.7797,39.4153,40.2158,\n",
    "38.9781,\n",
    "39.155,38.9514,38.4433,38.5503,38.1175,38.0831,38.3192,39.7983,39.9775,40.3397,40.6639]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个方法\n",
    "def Bilinear_interp(lonSta, latSta, longitude, latitude, var):\n",
    "    var_sta = []\n",
    "    for i in range(len(lonSta)):\n",
    "        iSta = np.searchsorted(longitude, lonSta[i]) \n",
    "        if longitude[iSta] > lonSta[i]:\n",
    "            iSta = iSta - 1 # 经度左下角点在经度array里的索引\n",
    "            \n",
    "        jSta = np.searchsorted(latitude, latSta[i])\n",
    "        if latitude[jSta] > latSta[i]:\n",
    "            jSta = jSta - 1 # 纬度左下角点在纬度array里的索引\n",
    "        \n",
    "        var11 = var[jSta, iSta]      #### t2m -> var\n",
    "        var21 = var[jSta, iSta+1]\n",
    "        var12 = var[jSta+1, iSta]\n",
    "        var22 = var[jSta+1, iSta+1]\n",
    "\n",
    "\t\t# 改变变量名，为了公式计算时候方便\n",
    "        x = lonSta[i]\n",
    "        y = latSta[i]\n",
    "        x1 = longitude[iSta]\n",
    "        x2 = longitude[iSta+1]\n",
    "        y1 = latitude[jSta]\n",
    "        y2 = latitude[jSta+1]\n",
    "        arg   = 1.0 / ((x2 - x1)*(y2 - y1))\n",
    "        arg11 = arg * (x2 - x) * (y2 - y) \n",
    "        arg21 = arg * (x - x1) * (y2 - y)\n",
    "        arg12 = arg * (x2 - x) * (y - y1)\n",
    "        arg22 = arg * (x - x1) * (y - y1)\n",
    "        var_interp = arg11*var11  + arg21*var21 + arg12*var12 + arg22*var22\n",
    "        var_sta.append(var_interp)\n",
    "    return var_sta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 插值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "var3_inter={}\n",
    "var3_list=['t_sta','r_sta','u_sta','v_sta','wspd_sta','wdir_sta','z_sta']\n",
    "for i in var3_list:\n",
    "    var3_inter[i]=np.zeros((dur,len(sta),27))\n",
    "\n",
    "var32_inter={}\n",
    "var32_list=['uheight_sta','vheight_sta']\n",
    "for i in var32_list:\n",
    "    var32_inter[i]=np.zeros((dur,len(sta),2))\n",
    "\n",
    "var2_inter={}\n",
    "var2_list=['u10_sta','v10_sta']\n",
    "for i in var2_list:\n",
    "    var2_inter[i]=np.zeros((dur,len(sta)))\n",
    "\n",
    "lat=r_time['latitude'].values\n",
    "lon=r_time['longitude'].values\n",
    "z_list=[6000,3000]\n",
    "for i in range(0,dur):###########################################################\n",
    "    wspd=sqrt( u_time[i,:,:,:]*u_time[i,:,:,:])+(v_time[i,:,:,:]*v_time[i,:,:,:] )\n",
    "    wdir=metpy.calc.wind_direction(u_time[i,:,:,:], v_time[i,:,:,:], convention='from')\n",
    "    u_height = interpz3d(u_time[i,:,:,:],z_time[i,:,:,:],np.array(z_list))\n",
    "    v_height = interpz3d(v_time[i,:,:,:],z_time[i,:,:,:],np.array(z_list))\n",
    "    for j in range(0,len(sta)):\n",
    "        for k in range(0,27):\n",
    "            var3_inter['t_sta'][i,j,k] = Bilinear_interp([sta_lon[j]], [sta_lat[j]], lon, lat, t_time[i,k,:,:])[0]\n",
    "            var3_inter['r_sta'][i,j,k] = Bilinear_interp([sta_lon[j]], [sta_lat[j]], lon, lat, r_time[i,k,:,:])[0]\n",
    "            var3_inter['u_sta'][i,j,k] = Bilinear_interp([sta_lon[j]], [sta_lat[j]], lon, lat, u_time[i,k,:,:])[0]\n",
    "            var3_inter['v_sta'][i,j,k] = Bilinear_interp([sta_lon[j]], [sta_lat[j]], lon, lat, v_time[i,k,:,:])[0]\n",
    "            var3_inter['z_sta'][i,j,k] = Bilinear_interp([sta_lon[j]], [sta_lat[j]], lon, lat, z_time[i,k,:,:])[0]\n",
    "            var3_inter['wspd_sta'][i,j,k] = Bilinear_interp([sta_lon[j]], [sta_lat[j]], lon, lat, wspd[k,:,:])[0]\n",
    "            var3_inter['wdir_sta'][i,j,k] = Bilinear_interp([sta_lon[j]], [sta_lat[j]], lon, lat, wdir[k,:,:])[0]\n",
    "        var2_inter['u10_sta'][i,j] = Bilinear_interp([sta_lon[j]], [sta_lat[j]], lon, lat, u10_time[i,:,:])[0]\n",
    "        var2_inter['v10_sta'][i,j] = Bilinear_interp([sta_lon[j]], [sta_lat[j]], lon, lat, v10_time[i,:,:])[0]\n",
    "        for k in range(0,2):\n",
    "            var32_inter['uheight_sta'][i,j,k] = Bilinear_interp([sta_lon[j]], [sta_lat[j]], lon, lat, u_height[k,:,:])[0]\n",
    "            var32_inter['vheight_sta'][i,j,k] = Bilinear_interp([sta_lon[j]], [sta_lat[j]], lon, lat, v_height[k,:,:])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sta_var={}\n",
    "for j in range(0,len(sta)):\n",
    "    sta_var[sta[j]]=pd.DataFrame(columns=['CAPE', 'LI', 'DCAPE','SWEAT','800-500','0-3KM','0-6KM'], index=time)\n",
    "    for i in range(0,dur):\n",
    "        t_mean=var3_inter['t_sta'][i,j,:]* units.degC\n",
    "        r_mean=var3_inter['r_sta'][i,j,:]* units.dimensionless\n",
    "        Td = dewpoint_from_relative_humidity(t_mean, r_mean)\n",
    "        prof= parcel_profile(p_time, t_mean[0], Td[0]).to('degC')\n",
    "        if (cape_cin(p_time, t_mean, Td, prof)[0].magnitude)>0:\n",
    "            sta_var[sta[j]]['CAPE'][i]=cape_cin(p_time, t_mean, Td, prof)[0].magnitude \n",
    "        else:\n",
    "            sta_var[sta[j]]['CAPE'][i]=0\n",
    "        # #LI\n",
    "        sta_var[sta[j]]['LI'][i]=metpy.calc.lifted_index(p_time, t_mean, prof, vertical_dim=0)[0].magnitude \n",
    "        # #DCAPE\n",
    "        sta_var[sta[j]]['DCAPE'][i]=downdraft_cape(p_time, t_mean, Td).magnitude\n",
    "        #sweat\n",
    "        sta_var[sta[j]]['SWEAT'][i]=metpy.calc.sweat_index(p_time,t_mean,Td,var3_inter['wspd_sta'][i,j,:]*units(\"m/s\"),var3_inter['wdir_sta'][i,j,:],vertical_dim=0)[0]\n",
    "        #xiangdangweiwen\n",
    "        sta_var[sta[j]]['800-500'][i] = equivalent_potential_temperature(p_time, t_mean, Td )[6].magnitude-equivalent_potential_temperature(p_time, t_mean, Td)[15].magnitude \n",
    "        #0-3km shear\n",
    "        sta_var[sta[j]]['0-3KM'][i]= ((var32_inter['uheight_sta'][i,j,1]-var2_inter['u10_sta'][i,j])**2+(var32_inter['vheight_sta'][i,j,1]-var2_inter['v10_sta'][i,j])**2)**(1/2)\n",
    "        #0-6km shear\n",
    "        sta_var[sta[j]]['0-6KM'][i]= ((var32_inter['uheight_sta'][i,j,0]-var2_inter['u10_sta'][i,j])**2+(var32_inter['vheight_sta'][i,j,0]-var2_inter['v10_sta'][i,j])**2)**(1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_output = \"/mnt/d/hpp_OneDrive/OneDrive/work/output/渤海中西部对流参数/test/\"+day+'/'\n",
    "if not os.path.exists(path_output):\n",
    "    os.makedirs(path_output)\n",
    "    \n",
    "matplotlib.rcParams['xtick.labelsize'] = 8\n",
    "matplotlib.rcParams['ytick.labelsize'] = 8\n",
    "matplotlib.rcParams[\"font.weight\"] = \"bold\"\n",
    "fontdict = {'fontsize': 12,'fontweight' : 800}\n",
    "fig,axs=plt.subplots(ncols=3,nrows=3,figsize=(24,10),sharey = False)\n",
    "axs[2,1].remove()\n",
    "axs[2,2].remove()\n",
    "axes = axs.flatten()\n",
    "for i,element in enumerate(var):\n",
    "    axes[i].plot(var_mean.iloc[:,i])\n",
    "    axes[i].set_title(var[i],fontdict=fontdict)\n",
    "    for x,y in zip(var_mean.index,var_mean.iloc[:,i]):\n",
    "        axes[i].text(x,y,'%.1f' % y,ha='center', va= 'bottom',fontdict={'fontsize':7})\n",
    "axs[2,0].set_xlabel('time(BJ)', fontsize =10,fontweight ='bold')\n",
    "fig.suptitle('mean',fontsize=15)\n",
    "plt.subplots_adjust(wspace=0.15,hspace=0.3)\n",
    "plt.savefig(path_output+\"区域.jpg\",dpi=600, bbox_inches='tight')\n",
    "\n",
    "for k in range(0,len(sta)-30):\n",
    "    fig,axs=plt.subplots(ncols=3,nrows=3,figsize=(24,10),sharey = False,sharex = False)\n",
    "    axs[2,1].remove()\n",
    "    axs[2,2].remove()\n",
    "    axes = axs.flatten()\n",
    "    for i,element in enumerate(var):\n",
    "        axes[i].plot(sta_var[sta[k]].iloc[:,i])\n",
    "        for x,y in zip(sta_var[sta[k]].index,sta_var[sta[k]].iloc[:,i]):\n",
    "            axes[i].text(x,y,'%.1f' % y,ha='center', va= 'bottom',fontdict={'fontsize':7})\n",
    "    fig.suptitle(sta[k],fontsize=15)\n",
    "    plt.subplots_adjust(wspace=0.15,hspace=0.3)\n",
    "    plt.savefig(path_output+sta[k]+\".jpg\",dpi=600, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 写文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_output = \"/mnt/d/hpp_onedrive/OneDrive/work/output/渤海中西部对流参数/test/\"\n",
    "path_output = \"/mnt/d/OneDrive/work/output/渤海中西部对流参数/test/\"\n",
    "sheet={}\n",
    "sheet_name=['sheet1','sheet2','sheet3','sheet4','sheet5','sheet6','sheet7']\n",
    "# path_output = \"/mnt/d/OneDrive/work/code/渤海中西部对流参数_excel/\"\n",
    "if not os.path.exists(path_output):\n",
    "    os.makedirs(path_output)\n",
    "f = xlwt.Workbook()\n",
    "for i,name in enumerate(sheet_name):\n",
    "    sheet[name]=f.add_sheet(var[i],cell_overwrite_ok=True) \n",
    "    sheet[name].write(0,1,'mean')\n",
    "    for j in range(0,len(time)):\n",
    "        sheet[name].write(j+1,1,float(var_mean.iloc[j,i]))\n",
    "        sheet[name].write(j+1,0,datetime.fromtimestamp(time[j].timestamp()).strftime(\"%d\")+datetime.fromtimestamp(time[j].timestamp()).strftime(\"%H\"))\n",
    "        for k in range(0,len(sta)):\n",
    "            sheet[name].write(0,k+2,sta[k])\n",
    "            sheet[name].write(j+1,k+2,sta_var[sta[k]].iloc[j,i])\n",
    "f.save(os.path.abspath(os.path.join(path_output)+day+'.xls'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
